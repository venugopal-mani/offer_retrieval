{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7052a266-bfcc-4041-8ce6-b90a01eed473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your search term:  walmart\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('arber, at walmart', 0.4558801829814911)\n",
      "('klondike cones at walmart', 0.43226851820945744)\n",
      "('flonase allergy relief, at walmart', 0.4224701106548309)\n",
      "('alevex™ at walmart', 0.4123484551906586)\n",
      "('klondike cones, spend $10 at walmart', 0.3940503656864166)\n",
      "('persil® proclean®, select varieties, at walmart', 0.37803092896938323)\n",
      "(\"michael angelo's® sauce at walmart\", 0.3756500422954559)\n",
      "('snuggle® liquid fabric softener, at walmart', 0.3741436779499054)\n",
      "('purex® laundry detergent, select varieties, at walmart', 0.37248298823833464)\n",
      "('cooked perfect® meatballs, at walmart', 0.3724797904491425)\n",
      "('bai® antioxidant, 6 pack, buy 2 at walmart', 0.3721838891506195)\n",
      "('core® hydration, select varieties, buy 2 at walmart', 0.36980671584606173)\n",
      "('country crock® plant based cream at walmart', 0.36921243071556087)\n",
      "('oxiclean™ laundry stain removers, select varieties at walmart', 0.3681399643421173)\n",
      "('bai® antioxidant, 6 pack, at walmart', 0.36796883642673495)\n",
      "('respawn® by 5® gum, at walmart', 0.36783827245235445)\n",
      "('tyson products, select varieties, spend $15 at walmart', 0.3668423891067505)\n",
      "('core® hydration, select varieties, at walmart', 0.36548614501953125)\n",
      "('country crock® plant based butter at walmart', 0.3623845219612122)\n",
      "('l’oréal paris men expert hair color, spend $9 at walmart', 0.36148858368396763)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fasttext\n",
    "\n",
    "# Read data from CSV files into dataframes\n",
    "df1 = pd.read_csv(\"data/brand_category.csv\")\n",
    "df2 = pd.read_csv(\"data/categories.csv\")\n",
    "df3 = pd.read_csv(\"data/offer_retailer.csv\")\n",
    "\n",
    "# Data preprocessing for df3 dataframe\n",
    "df3['OFFER'] = df3['OFFER'].str.strip()  # Remove leading and trailing whitespaces\n",
    "df3['OFFER'] = df3['OFFER'].str.lower()  # Convert 'OFFER' column values to lowercase\n",
    "df3['RETAILER'] = df3['RETAILER'].fillna('')  # Fill missing values in 'RETAILER' column with empty string\n",
    "df3['BRAND'] = df3['BRAND'].fillna('')  # Fill missing values in 'BRAND' column with empty string\n",
    "\n",
    "# Group by 'OFFER' column and aggregate 'BRAND' and 'RETAILER' values\n",
    "df3 = df3.groupby('OFFER').agg({\n",
    "    'BRAND': lambda x: ' '.join(pd.Series(x).drop_duplicates()),  # Join unique 'BRAND' values with space\n",
    "    'RETAILER': lambda x: ' '.join(pd.Series(x).drop_duplicates())  # Join unique 'RETAILER' values with space\n",
    "}).reset_index()  # Reset index after grouping\n",
    "\n",
    "# Create dictionaries mapping 'OFFER' to 'BRAND' and 'OFFER' to 'RETAILER'\n",
    "offer_retailer_dict = dict(zip(df3['OFFER'], df3['RETAILER']))\n",
    "offer_brand_dict = dict(zip(df3['OFFER'], df3['BRAND']))\n",
    "\n",
    "# Merge df1 and df2 dataframes based on columns 'BRAND_BELONGS_TO_CATEGORY' and 'PRODUCT_CATEGORY'\n",
    "merged_df = pd.merge(df1, df2, left_on='BRAND_BELONGS_TO_CATEGORY', right_on='PRODUCT_CATEGORY', how='left')\n",
    "\n",
    "# Group by 'BRAND' column and aggregate 'PRODUCT_CATEGORY' and 'IS_CHILD_CATEGORY_TO' values\n",
    "grouped_df = merged_df.groupby('BRAND').agg({\n",
    "    'PRODUCT_CATEGORY': lambda x: ' '.join(pd.Series(x).drop_duplicates()),  # Join unique 'PRODUCT_CATEGORY' values with space\n",
    "    'IS_CHILD_CATEGORY_TO': lambda x: ' '.join(pd.Series(x).drop_duplicates())  # Join unique 'IS_CHILD_CATEGORY_TO' values with space\n",
    "}).reset_index()  # Reset index after grouping\n",
    "\n",
    "# Merge df3 and grouped_df dataframes based on 'BRAND' column\n",
    "merged_df = pd.merge(df3, grouped_df, on='BRAND', how='left')\n",
    "\n",
    "# Fill missing values in specific columns\n",
    "merged_df['RETAILER'] = merged_df['RETAILER'].fillna('')  # Fill missing values in 'RETAILER' column with empty string\n",
    "merged_df['PRODUCT_CATEGORY'] = merged_df['PRODUCT_CATEGORY'].fillna('')  # Fill missing values in 'PRODUCT_CATEGORY' column with empty string\n",
    "merged_df['IS_CHILD_CATEGORY_TO'] = merged_df['IS_CHILD_CATEGORY_TO'].fillna('')  # Fill missing values in 'IS_CHILD_CATEGORY_TO' column with empty string\n",
    "merged_df['BRAND'] = merged_df['BRAND'].fillna('')  # Fill missing values in 'BRAND' column with empty string\n",
    "\n",
    "# Group by 'OFFER' column and aggregate 'BRAND', 'PRODUCT_CATEGORY', 'IS_CHILD_CATEGORY_TO', and 'RETAILER' values\n",
    "grouped_df = merged_df.groupby('OFFER').agg({\n",
    "    'BRAND': lambda x: ', '.join(pd.Series(x).drop_duplicates()),  # Join unique 'BRAND' values with comma\n",
    "    'PRODUCT_CATEGORY': lambda x: ', '.join(pd.Series(x).drop_duplicates()),  # Join unique 'PRODUCT_CATEGORY' values with comma\n",
    "    'IS_CHILD_CATEGORY_TO': lambda x: ', '.join(pd.Series(x).drop_duplicates()),  # Join unique 'IS_CHILD_CATEGORY_TO' values with comma\n",
    "    'RETAILER': lambda x: ', '.join(pd.Series(x).drop_duplicates())  # Join unique 'RETAILER' values with comma\n",
    "}).reset_index()  # Reset index after grouping\n",
    "\n",
    "# Create 'OFFER_TEXT' column by combining various columns with space and comma separators\n",
    "grouped_df['OFFER_TEXT'] = grouped_df.apply(lambda x: '%s %s %s %s %s' % (x['OFFER'], x['BRAND'], x['IS_CHILD_CATEGORY_TO'], x['BRAND'], x['RETAILER']), axis=1)\n",
    "\n",
    "# Create dictionary mapping 'OFFER' to 'OFFER_TEXT'\n",
    "offer_dict = dict(zip(grouped_df['OFFER'], grouped_df['OFFER_TEXT']))\n",
    "\n",
    "# Load fastText model\n",
    "fasttext_model_path = './fastText/cc.en.300.bin'\n",
    "fasttext_model = fasttext.load_model(fasttext_model_path)\n",
    "\n",
    "def get_phrase_vector_fasttext(phrase, fasttext_model):\n",
    "    \"\"\"\n",
    "    Get the vector representation of a phrase using fastText model.\n",
    "\n",
    "    Parameters:\n",
    "    phrase (str): The input phrase to be vectorized.\n",
    "    fasttext_model: The pre-trained fastText model.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Vector representation of the input phrase.\n",
    "    \"\"\"\n",
    "    # Get the vector for the entire phrase\n",
    "    phrase_vector = fasttext_model.get_sentence_vector(phrase)\n",
    "    return phrase_vector\n",
    "\n",
    "def get_matches(phrase1, phrase2):\n",
    "    \"\"\"\n",
    "    Calculate the dot product of vectors representing two phrases.\n",
    "\n",
    "    Parameters:\n",
    "    phrase1 (str): First input phrase.\n",
    "    phrase2 (str): Second input phrase.\n",
    "\n",
    "    Returns:\n",
    "    float: Dot product of the vectors representing the input phrases.\n",
    "    \"\"\"\n",
    "    vect1 = get_phrase_vector_fasttext(phrase1, fasttext_model)\n",
    "    vect2 = get_phrase_vector_fasttext(phrase2, fasttext_model)\n",
    "    return np.dot(vect1, vect2)\n",
    "    #return cosine_similarity(phrase1, phrase2)\n",
    "\n",
    "def get_best_offers(search_term):\n",
    "    \"\"\"\n",
    "    Get the best matching offers based on the input search term.\n",
    "\n",
    "    Parameters:\n",
    "    search_term (str): The search term entered by the user.\n",
    "\n",
    "    Returns:\n",
    "    list: List of tuples containing the best matching offers and their scores, sorted in descending order of scores.\n",
    "    \"\"\"\n",
    "    final_result = []\n",
    "    for i in offer_dict.keys():\n",
    "        offer_text = offer_dict[i]\n",
    "        offer_text = offer_text.replace('\\n', '')\n",
    "        offer_retailer_text = offer_retailer_dict[i]\n",
    "        offer_brand_text = offer_brand_dict[i]\n",
    "        score1 = get_matches(search_term, offer_text)\n",
    "        score2 = get_matches(search_term, offer_retailer_text)\n",
    "        i = i.replace('\\n', '')\n",
    "        score3 = get_matches(search_term, i)\n",
    "        ans = 0.4 * score1 + 0.4 * score2 + 0.2 * score3\n",
    "        if ans > 0.10 and score3 > 0.10:\n",
    "            final_result.append((i, ans))\n",
    "    final_result = sorted(final_result, key=lambda x: x[1], reverse=True)\n",
    "    return final_result\n",
    "\n",
    "# Get user input for search term\n",
    "query = input(\"Enter your search term: \")\n",
    "\n",
    "# Get and display the best matching offers\n",
    "ans = get_best_offers(query)\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    print(ans[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e87d8ec-5c1b-4112-bf70-98b3b094acfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
